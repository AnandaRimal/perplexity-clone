{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "cf1880ab",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\anand\\Desktop\\perplexiy\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
                        "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from typing import TypedDict, Annotated, List\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
                "from langchain_community.tools.tavily_search import TavilySearchResults\n",
                "\n",
                "from langgraph.graph import StateGraph, END\n",
                "from langgraph.graph.message import add_messages\n",
                "from langgraph.prebuilt import ToolNode\n",
                "from langgraph.checkpoint.memory import MemorySaver"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "2401781e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "390a2412",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Agent State\n",
                "# ---------------------------------------------------------\n",
                "class AgentState(TypedDict):\n",
                "    messages: Annotated[List[BaseMessage], add_messages]\n",
                "\n",
                "# ---------------------------------------------------------"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "60aafe32",
            "metadata": {},
            "outputs": [],
            "source": [
                "# LLM Setup\n",
                "# ---------------------------------------------------------\n",
                "llm = ChatGoogleGenerativeAI(\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    temperature=0.2,\n",
                "    convert_system_message_to_human=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "5cf68181",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\anand\\AppData\\Local\\Temp\\ipykernel_119120\\3241713405.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
                        "  search_tool = TavilySearchResults(max_results=2)\n"
                    ]
                }
            ],
            "source": [
                "# Tools\n",
                "# ---------------------------------------------------------\n",
                "search_tool = TavilySearchResults(max_results=2)\n",
                "search_tool.name = \"tavily_search\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "ec79c90a",
            "metadata": {},
            "outputs": [],
            "source": [
                "tools = [search_tool]\n",
                "llm_with_tools = llm.bind_tools(tools)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "b95aca97",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Agent Node\n",
                "# ---------------------------------------------------------\n",
                "def agent_node(state: AgentState):\n",
                "    from datetime import datetime\n",
                "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
                "    \n",
                "    system_prompt = SystemMessage(f\"\"\"\n",
                "You are a helpful AI assistant. Today's date is {current_date}.\n",
                "\n",
                "- For casual chat, answer normally.\n",
                "- For factual questions, news, or anything requiring updated information,\n",
                "  CALL the `tavily_search` tool.\n",
                "\"\"\")\n",
                "\n",
                "    messages = [system_prompt] + state[\"messages\"]\n",
                "    ai_reply = llm_with_tools.invoke(messages)\n",
                "\n",
                "    return {\"messages\": [ai_reply]}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "2c7df751",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# Should Continue (Tool or End)\n",
                "# ---------------------------------------------------------\n",
                "def should_continue(state: AgentState):\n",
                "    last = state[\"messages\"][-1]\n",
                "    return \"tools\" if last.tool_calls else \"__end__\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34b8b661",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Bot is ready! Type 'exit' to stop.\n",
                        "Agent: Hello! How can I help you today?\n"
                    ]
                }
            ],
            "source": [
                "# ---------------------------------------------------------\n",
                "# Create Graph\n",
                "# ---------------------------------------------------------\n",
                "\n",
                "graph = StateGraph(AgentState)\n",
                "\n",
                "graph.add_node(\"agent\", agent_node)\n",
                "graph.add_node(\"tools\", ToolNode(tools))\n",
                "\n",
                "graph.set_entry_point(\"agent\")\n",
                "\n",
                "graph.add_conditional_edges(\n",
                "        \"agent\",\n",
                "        should_continue,\n",
                "        {\n",
                "            \"tools\": \"tools\",\n",
                "            \"__end__\": END\n",
                "        }\n",
                "    )\n",
                "\n",
                "graph.add_edge(\"tools\", \"agent\")\n",
                "\n",
                "# Initialize MemorySaver\n",
                "memory = MemorySaver()\n",
                "\n",
                "# Compile with checkpointer\n",
                "app = graph.compile(checkpointer=memory)\n",
                "\n",
                "# Interactive Loop\n",
                "print(\"Bot is ready! Type 'exit' to stop.\")\n",
                "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
                "\n",
                "while True:\n",
                "    user_input = input(\"User: \")\n",
                "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
                "        print(\"Goodbye!\")\n",
                "        break\n",
                "    \n",
                "    response = app.invoke(\n",
                "        {\"messages\": [HumanMessage(content=user_input)]},\n",
                "        config=config\n",
                "    )\n",
                "    \n",
                "    print(\"Agent:\", response[\"messages\"][-1].content)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7f3c7b5",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
