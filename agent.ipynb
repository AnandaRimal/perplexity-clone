{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "cf1880ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from typing import TypedDict, Annotated, List\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "from langchain_google_genai import ChatGoogleGenerativeAI\n",
                "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
                "from langchain_community.tools.tavily_search import TavilySearchResults\n",
                "\n",
                "from langgraph.graph import StateGraph, END\n",
                "from langgraph.graph.message import add_messages\n",
                "from langgraph.prebuilt import ToolNode"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "2401781e",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 21,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "load_dotenv()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "id": "390a2412",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Agent State\n",
                "# ---------------------------------------------------------\n",
                "class AgentState(TypedDict):\n",
                "    messages: Annotated[List[BaseMessage], add_messages]\n",
                "\n",
                "# ---------------------------------------------------------"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "id": "60aafe32",
            "metadata": {},
            "outputs": [],
            "source": [
                "# LLM Setup\n",
                "# ---------------------------------------------------------\n",
                "llm = ChatGoogleGenerativeAI(\n",
                "    model=\"gemini-2.5-flash\",\n",
                "    temperature=0.2,\n",
                "    convert_system_message_to_human=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "id": "5cf68181",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tools\n",
                "# ---------------------------------------------------------\n",
                "search_tool = TavilySearchResults(max_results=2)\n",
                "search_tool.name = \"tavily_search\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "id": "ec79c90a",
            "metadata": {},
            "outputs": [],
            "source": [
                "tools = [search_tool]\n",
                "llm_with_tools = llm.bind_tools(tools)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "b95aca97",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Agent Node\n",
                "# ---------------------------------------------------------\n",
                "def agent_node(state: AgentState):\n",
                "    from datetime import datetime\n",
                "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
                "    \n",
                "    system_prompt = SystemMessage(f\"\"\"\n",
                "You are a helpful AI assistant. Today's date is {current_date}.\n",
                "\n",
                "- For casual chat, answer normally.\n",
                "- For factual questions, news, or anything requiring updated information,\n",
                "  CALL the `tavily_search` tool.\n",
                "\"\"\")\n",
                "\n",
                "    messages = [system_prompt] + state[\"messages\"]\n",
                "    ai_reply = llm_with_tools.invoke(messages)\n",
                "\n",
                "    return {\"messages\": [ai_reply]}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "2c7df751",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# Should Continue (Tool or End)\n",
                "# ---------------------------------------------------------\n",
                "def should_continue(state: AgentState):\n",
                "    last = state[\"messages\"][-1]\n",
                "    return \"tools\" if last.tool_calls else \"__end__\"\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34b8b661",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ---------------------------------------------------------\n",
                "# Create Graph\n",
                "# ---------------------------------------------------------\n",
                "\n",
                "graph = StateGraph(AgentState)\n",
                "\n",
                "graph.add_node(\"agent\", agent_node)\n",
                "graph.add_node(\"tools\", ToolNode(tools))\n",
                "\n",
                "graph.set_entry_point(\"agent\")\n",
                "\n",
                "graph.add_conditional_edges(\n",
                "        \"agent\",\n",
                "        should_continue,\n",
                "        {\n",
                "            \"tools\": \"tools\",\n",
                "            \"__end__\": END\n",
                "        }\n",
                "    )\n",
                "\n",
                "graph.add_edge(\"tools\", \"agent\")\n",
                "\n",
                "app = graph.compile()\n",
                "\n",
                "# Correct invocation\n",
                "response = app.invoke({\n",
                "    \"messages\": [HumanMessage(content=\"hello\")]\n",
                "})\n",
                "\n",
                "# Correct output printing\n",
                "print(response[\"messages\"][-1].content)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a7f3c7b5",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
